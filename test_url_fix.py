#!/usr/bin/env python3
"""
URLä¿®æ­£ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

é’ç©ºæ–‡åº«ä½œå®¶URLã®å½¢å¼ãŒæ­£ã—ãä¿®æ­£ã•ã‚Œã¦ã„ã‚‹ã‹ãƒ†ã‚¹ãƒˆã—ã¾ã™
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from extractors.author_list_scraper import AuthorListScraper

def test_url_fix():
    """URLä¿®æ­£ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”— é’ç©ºæ–‡åº«ä½œå®¶URLä¿®æ­£ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    try:
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–
        scraper = AuthorListScraper(rate_limit=0.5)
        
        # å°‘æ•°ã®ä½œå®¶æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ†ã‚¹ãƒˆ
        print("ğŸ“š ä½œå®¶æƒ…å ±ã‚’å–å¾—ä¸­ï¼ˆæœ€åˆã®20åã§ãƒ†ã‚¹ãƒˆï¼‰...")
        authors = scraper.fetch_all_authors()
        
        if not authors:
            print("âŒ ä½œå®¶æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # æœ€åˆã®20åã‚’ãƒ†ã‚¹ãƒˆ
        test_authors = authors[:20]
        print(f"âœ… {len(test_authors)}åã‚’ãƒ†ã‚¹ãƒˆ")
        
        print("\nğŸ” URLæ¤œè¨¼çµæœ:")
        print("-" * 80)
        
        correct_urls = 0
        incorrect_urls = 0
        
        for i, author in enumerate(test_authors, 1):
            url = author.author_url
            
            # æ­£ã—ã„URLå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
            expected_pattern = "https://www.aozora.gr.jp/index_pages/person"
            if url and expected_pattern in url:
                status = "âœ…"
                correct_urls += 1
            else:
                status = "âŒ"
                incorrect_urls += 1
            
            print(f"{i:2}. {status} {author.name}")
            print(f"    URL: {url}")
            
            # æ¢¶äº•åŸºæ¬¡éƒã‚’ç‰¹ã«ç¢ºèª
            if "æ¢¶äº•" in author.name:
                print(f"    ğŸ¯ æ¢¶äº•åŸºæ¬¡éƒã®URLç¢ºèª:")
                expected_kajii_url = "https://www.aozora.gr.jp/index_pages/person74.html"
                if url == expected_kajii_url:
                    print(f"    âœ… æ­£ã—ã„URL: {url}")
                else:
                    print(f"    âŒ æœŸå¾…å€¤: {expected_kajii_url}")
                    print(f"    âŒ å®Ÿéš›å€¤: {url}")
        
        print("\n" + "=" * 50)
        print("ğŸ“Š URLæ¤œè¨¼ã‚µãƒãƒªãƒ¼")
        print("=" * 50)
        print(f"æ­£ã—ã„URL: {correct_urls}ä»¶")
        print(f"é–“é•ã£ãŸURL: {incorrect_urls}ä»¶")
        print(f"æˆåŠŸç‡: {correct_urls/(correct_urls+incorrect_urls)*100:.1f}%")
        
        if incorrect_urls == 0:
            print("ğŸ‰ å…¨ã¦ã®URLãŒæ­£ã—ã„å½¢å¼ã§ã™ï¼")
        else:
            print("âš ï¸  ã„ãã¤ã‹ã®URLã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_url_fix() 