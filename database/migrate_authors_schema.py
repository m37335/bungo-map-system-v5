#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
authorsãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒæ›´æ–°ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
é’ç©ºæ–‡åº«å¯¾å¿œãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
"""

import sqlite3
import sys
import os
from datetime import datetime

def migrate_authors_table(db_path: str = "data/bungo_map.db"):
    """authorsãƒ†ãƒ¼ãƒ–ãƒ«ã«é’ç©ºæ–‡åº«é–¢é€£ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ """
    print("ğŸ”§ authorsãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒæ›´æ–°é–‹å§‹")
    print("=" * 60)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ç¾åœ¨ã®ã‚¹ã‚­ãƒ¼ãƒç¢ºèª
        print("ğŸ“Š ç¾åœ¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :")
        cursor.execute("PRAGMA table_info(authors);")
        current_columns = cursor.fetchall()
        existing_column_names = [col[1] for col in current_columns]
        
        for col in current_columns:
            print(f"  {col[1]} {col[2]} {'NOT NULL' if col[3] else ''} {'PK' if col[5] else ''}")
        
        # è¿½åŠ ã™ã‚‹ã‚«ãƒ©ãƒ å®šç¾©
        new_columns = [
            ("author_name_kana", "VARCHAR(255)"),
            ("period", "VARCHAR(50)"),
            ("description", "TEXT"),
            ("portrait_url", "VARCHAR(512)"),
            ("copyright_status", "VARCHAR(20)", "DEFAULT 'expired'"),
            ("aozora_works_count", "INTEGER", "DEFAULT 0"),
            ("alias_info", "TEXT"),
            ("section", "VARCHAR(10)"),
            ("works_count", "INTEGER", "DEFAULT 0"),
            ("total_sentences", "INTEGER", "DEFAULT 0"),
            ("source_system", "VARCHAR(50)", "DEFAULT 'v4.0'"),
            ("verification_status", "VARCHAR(20)", "DEFAULT 'pending'")
        ]
        
        # ã‚«ãƒ©ãƒ è¿½åŠ å®Ÿè¡Œ
        print(f"\nğŸ”¨ ã‚«ãƒ©ãƒ è¿½åŠ å®Ÿè¡Œ:")
        added_count = 0
        
        for column_def in new_columns:
            column_name = column_def[0]
            column_type = column_def[1]
            column_extra = column_def[2] if len(column_def) > 2 else ""
            
            if column_name not in existing_column_names:
                try:
                    alter_sql = f"ALTER TABLE authors ADD COLUMN {column_name} {column_type} {column_extra}"
                    print(f"  + {column_name} {column_type} {column_extra}")
                    cursor.execute(alter_sql)
                    added_count += 1
                except Exception as e:
                    print(f"  âŒ {column_name}: {e}")
            else:
                print(f"  â­ï¸  {column_name}: æ—¢å­˜")
        
        # aozora_author_urlã®ã‚µã‚¤ã‚ºæ‹¡å¼µï¼ˆæ—¢å­˜ã‚«ãƒ©ãƒ ãªã®ã§åˆ¥é€”å¯¾å¿œãŒå¿…è¦ï¼‰
        print(f"\nğŸ”§ æ—¢å­˜ã‚«ãƒ©ãƒ ã®æœ€é©åŒ–:")
        try:
            # SQLiteã§ã¯ã‚«ãƒ©ãƒ ã‚µã‚¤ã‚ºå¤‰æ›´ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã¯æ³¨æ„
            print(f"  â„¹ï¸  aozora_author_url: ã‚µã‚¤ã‚ºæ‹¡å¼µã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆè¤‡é›‘ãªãŸã‚ã€ç¾åœ¨ã®ã¾ã¾ä½¿ç”¨")
        except Exception as e:
            print(f"  âš ï¸  aozora_author_urlæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ 
        print(f"\nğŸ“‡ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ :")
        indexes_to_add = [
            ("idx_authors_section", "section"),
            ("idx_authors_copyright", "copyright_status"),
            ("idx_authors_source", "source_system")
        ]
        
        for index_name, column_name in indexes_to_add:
            try:
                cursor.execute(f"CREATE INDEX IF NOT EXISTS {index_name} ON authors({column_name})")
                print(f"  âœ… {index_name}: {column_name}")
            except Exception as e:
                print(f"  âŒ {index_name}: {e}")
        
        # å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
        conn.commit()
        
        # æ›´æ–°å¾Œã®ã‚¹ã‚­ãƒ¼ãƒç¢ºèª
        print(f"\nğŸ“Š æ›´æ–°å¾Œã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :")
        cursor.execute("PRAGMA table_info(authors);")
        updated_columns = cursor.fetchall()
        
        for col in updated_columns:
            print(f"  {col[1]} {col[2]} {'NOT NULL' if col[3] else ''} {'PK' if col[5] else ''}")
        
        print(f"\nâœ… ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
        print(f"  è¿½åŠ ã‚«ãƒ©ãƒ : {added_count}å€‹")
        print(f"  ç·ã‚«ãƒ©ãƒ æ•°: {len(updated_columns)}å€‹")
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        if 'conn' in locals():
            conn.rollback()
        return False
        
    finally:
        if 'conn' in locals():
            conn.close()

def verify_schema_compatibility():
    """SQLAlchemyãƒ¢ãƒ‡ãƒ«ã¨ã®äº’æ›æ€§ç¢ºèª"""
    print(f"\nğŸ” ã‚¹ã‚­ãƒ¼ãƒäº’æ›æ€§ç¢ºèª:")
    
    try:
        # SQLAlchemyãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æœŸå¾…ã•ã‚Œã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å–å¾—
        from database.models import Author
        
        # SQLAlchemyãƒ¢ãƒ‡ãƒ«ã®ã‚«ãƒ©ãƒ ä¸€è¦§å–å¾—
        expected_columns = []
        for column in Author.__table__.columns:
            expected_columns.append(column.name)
        
        print(f"  SQLAlchemyãƒ¢ãƒ‡ãƒ«æœŸå¾…ã‚«ãƒ©ãƒ : {len(expected_columns)}å€‹")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å®Ÿéš›ã®ã‚«ãƒ©ãƒ ç¢ºèª
        conn = sqlite3.connect("data/bungo_map.db")
        cursor = conn.cursor()
        cursor.execute("PRAGMA table_info(authors);")
        actual_columns = [col[1] for col in cursor.fetchall()]
        conn.close()
        
        print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Ÿéš›ã‚«ãƒ©ãƒ : {len(actual_columns)}å€‹")
        
        # å·®åˆ†ç¢ºèª
        missing_in_db = set(expected_columns) - set(actual_columns)
        extra_in_db = set(actual_columns) - set(expected_columns)
        
        if missing_in_db:
            print(f"  âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¸è¶³: {list(missing_in_db)}")
        
        if extra_in_db:
            print(f"  â„¹ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä½™åˆ†: {list(extra_in_db)}")
        
        if not missing_in_db and not extra_in_db:
            print(f"  âœ… å®Œå…¨äº’æ›")
            return True
        else:
            print(f"  âš ï¸  éƒ¨åˆ†äº’æ›ï¼ˆæ©Ÿèƒ½ä¸Šã¯å•é¡Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")
            return len(missing_in_db) == 0  # ä¸è¶³ãŒãªã‘ã‚Œã°OK
            
    except Exception as e:
        print(f"  âŒ äº’æ›æ€§ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='authorsãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒæ›´æ–°')
    parser.add_argument('--db-path', default='data/bungo_map.db', help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--verify-only', action='store_true', help='äº’æ›æ€§ç¢ºèªã®ã¿å®Ÿè¡Œ')
    
    args = parser.parse_args()
    
    if args.verify_only:
        verify_schema_compatibility()
    else:
        print(f"ğŸ¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {args.db_path}")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¨å¥¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print(f"\nâš ï¸  é‡è¦: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’æ¨å¥¨ã—ã¾ã™")
        print(f"  cp {args.db_path} {args.db_path}.backup_$(date +%Y%m%d_%H%M%S)")
        
        response = input(f"\nâ“ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        if response not in ['y', 'yes']:
            print("âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        success = migrate_authors_table(args.db_path)
        
        if success:
            print(f"\nğŸ‰ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸï¼")
            verify_schema_compatibility()
        else:
            print(f"\nğŸ’¥ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—")

if __name__ == "__main__":
    main() 