#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Wikipediaä½œè€…æƒ…å ±è‡ªå‹•è£œå®Œã‚·ã‚¹ãƒ†ãƒ  v4.0
æ—¢å­˜ã®ä½œè€…ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç”Ÿå¹´ãƒ»æ²¡å¹´ç­‰ã‚’è‡ªå‹•è£œå®Œ
"""

import re
import requests
import wikipedia
from typing import List, Dict, Optional, Tuple
from bs4 import BeautifulSoup
import time
import json
from datetime import datetime
import sys
import os
import argparse

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from database.manager import DatabaseManager


class WikipediaAuthorEnricher:
    """Wikipedia ã‹ã‚‰ä½œè€…æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’è£œå®Œ"""
    
    def __init__(self):
        # Wikipediaè¨€èªè¨­å®š
        wikipedia.set_lang("ja")
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'BungoMapBot/4.0 (bungo-map@example.com)'
        })
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        self.db = DatabaseManager()
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_authors': 0,
            'success_count': 0,
            'failure_count': 0,
            'birth_year_updated': 0,
            'death_year_updated': 0,
            'wikipedia_url_updated': 0,
            'processing_time': 0.0
        }
        
    def search_author_wikipedia(self, author_name: str) -> Optional[Dict]:
        """ä½œè€…ã®Wikipediaæƒ…å ±ã‚’è©³ç´°æ¤œç´¢ï¼ˆæ–‡è±ªç‰¹åŒ–ç‰ˆï¼‰"""
        try:
            print(f"ğŸ” {author_name} ã®æƒ…å ±ã‚’æ¤œç´¢ä¸­...")
            
            # æ–‡è±ªå‘ã‘ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå„ªå…ˆé †ä½é †ï¼‰
            search_keywords = [
                author_name,  # åŸºæœ¬ã®ä½œå®¶åã‚’æœ€å„ªå…ˆ
                f"{author_name} ä½œå®¶",
                f"{author_name} å°èª¬å®¶", 
                f"{author_name} æ–‡å­¦è€…",
                f"{author_name} è©©äºº",
                f"{author_name} æ˜æ²»",
                f"{author_name} å¤§æ­£",
                f"{author_name} æ˜­å’Œ"
            ]
            
            for keyword in search_keywords:
                try:
                    # Wikipediaæ¤œç´¢
                    page = wikipedia.page(keyword)
                    
                    # åŸºæœ¬æƒ…å ±æŠ½å‡º
                    extract = page.summary
                    birth_year, death_year = self._extract_life_years(extract, page.content)
                    
                    # æ–‡è±ªã®å¹´ä»£ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚Šå³æ ¼ã«ï¼‰
                    if birth_year and (1850 <= birth_year <= 1920) and self._is_literary_figure(extract):
                        return {
                            'title': page.title,
                            'url': page.url,
                            'extract': extract[:500],  # è¦ç´„ï¼ˆ500æ–‡å­—ï¼‰
                            'content': page.content,
                            'birth_year': birth_year,
                            'death_year': death_year,
                            'search_keyword': keyword
                        }
                    
                except wikipedia.exceptions.DisambiguationError as e:
                    # æ›–æ˜§ã•å›é¿ãƒšãƒ¼ã‚¸ã®å ´åˆã€é©åˆ‡ãªå€™è£œã‚’é¸æŠ
                    best_option = self._select_best_literary_option(author_name, e.options)
                    if best_option:
                        try:
                            page = wikipedia.page(best_option)
                            extract = page.summary
                            birth_year, death_year = self._extract_life_years(extract, page.content)
                            
                            # æ–‡è±ªã®å¹´ä»£ãƒã‚§ãƒƒã‚¯
                            if birth_year and (1850 <= birth_year <= 1920) and self._is_literary_figure(extract):
                                return {
                                    'title': page.title,
                                    'url': page.url,
                                    'extract': extract[:500],
                                    'content': page.content,
                                    'birth_year': birth_year,
                                    'death_year': death_year,
                                    'search_keyword': keyword,
                                    'disambiguation_option': best_option
                                }
                        except Exception as e2:
                            print(f"âš ï¸ æ›–æ˜§ã•å›é¿å€™è£œã‚¨ãƒ©ãƒ¼ ({best_option}): {e2}")
                            continue
                    
                except wikipedia.exceptions.PageError:
                    continue  # æ¬¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è©¦ã™
                    
                except Exception as e:
                    print(f"âš ï¸ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            print(f"âš ï¸ {author_name} ã®é©åˆ‡ãªWikipediaãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None
            
        except Exception as e:
            print(f"âš ï¸ Wikipediaæ¤œç´¢ã‚¨ãƒ©ãƒ¼ ({author_name}): {e}")
            return None
    
    def _is_literary_figure(self, extract: str) -> bool:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ–‡å­¦è€…ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        literary_keywords = [
            'ä½œå®¶', 'å°èª¬å®¶', 'è©©äºº', 'æ–‡å­¦è€…', 'æ­Œäºº', 'ä¿³äºº',
            'å°èª¬', 'è©©', 'æ–‡å­¦', 'ä½œå“', 'è‘—ä½œ', 'åŸ·ç­†',
            'æ˜æ²»æ–‡å­¦', 'å¤§æ­£æ–‡å­¦', 'æ˜­å’Œæ–‡å­¦', 'è¿‘ä»£æ–‡å­¦',
            'é’ç©ºæ–‡åº«', 'ãƒ—ãƒ­ãƒ¬ã‚¿ãƒªã‚¢æ–‡å­¦', 'è‡ªç„¶ä¸»ç¾©'
        ]
        
        # æ–‡å­¦é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        for keyword in literary_keywords:
            if keyword in extract:
                return True
        return False
    
    def _select_best_literary_option(self, author_name: str, options: List[str]) -> Optional[str]:
        """æ›–æ˜§ã•å›é¿ãƒšãƒ¼ã‚¸ã‹ã‚‰æ–‡è±ªã¨ã—ã¦æœ€é©ãªé¸æŠè‚¢ã‚’é¸ã¶"""
        # æ–‡å­¦è€…å‘ã‘ã®å„ªå…ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        priority_keywords = [
            'ä½œå®¶', 'å°èª¬å®¶', 'è©©äºº', 'æ–‡å­¦è€…', 'æ­Œäºº', 'ä¿³äºº',
            'æ˜æ²»', 'å¤§æ­£', 'æ˜­å’Œ', 'æ–‡å­¦', 'å°èª¬', 'è©©'
        ]
        
        # é¿ã‘ã‚‹ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆåŒåç•°äººã‚’æ’é™¤ï¼‰
        avoid_keywords = [
            'æ¤ç‰©å­¦è€…', 'åšå£«', 'å­¦è€…', 'ç ”ç©¶è€…', 'æ•™æˆ', 'åŒ»å¸«',
            'æ”¿æ²»å®¶', 'å®Ÿæ¥­å®¶', 'è»äºº', 'å®˜åƒš', 'ç¾ä»£', 'å¹³æˆ'
        ]
        
        # ã¾ãšé¿ã‘ã‚‹ã¹ãã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’é™¤å¤–
        filtered_options = []
        for option in options:
            should_avoid = False
            for avoid_word in avoid_keywords:
                if avoid_word in option:
                    should_avoid = True
                    break
            if not should_avoid:
                filtered_options.append(option)
        
        # å„ªå…ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹é¸æŠè‚¢ã‚’æ¢ã™
        for keyword in priority_keywords:
            for option in filtered_options:
                if keyword in option:
                    return option
        
        # å„ªå…ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€é™¤å¤–ã—ãªã‹ã£ãŸæœ€åˆã®é¸æŠè‚¢
        return filtered_options[0] if filtered_options else None
    
    def _extract_life_years(self, summary: str, content: str) -> Tuple[Optional[int], Optional[int]]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”Ÿå¹´ãƒ»æ²¡å¹´ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # summaryã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ï¼ˆã‚ˆã‚Šæ­£ç¢ºï¼‰
        text = summary[:1000] + " " + content[:1000]
        
        # æœ€ã‚‚ç¢ºå®Ÿãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é †ã«è©¦ã™
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: 1862å¹´5æœˆ22æ—¥ã€ˆæ–‡ä¹…2å¹´4æœˆ24æ—¥ã€‰ - 1957å¹´ã€ˆæ˜­å’Œ32å¹´ã€‰1æœˆ18æ—¥ å½¢å¼
        life_span_patterns = [
            r'(\d{4})å¹´.*?ã€ˆ.*?ã€‰.*?-\s*(\d{4})å¹´',  # ç‰§é‡å¯Œå¤ªéƒã®å½¢å¼
            r'(\d{4})å¹´.*?æœˆ.*?æ—¥.*?-\s*(\d{4})å¹´.*?æœˆ.*?æ—¥',  # è©³ç´°æ—¥ä»˜å½¢å¼
            r'ï¼ˆ(\d{4})å¹´.*?-.*?(\d{4})å¹´.*?ï¼‰',  # æ‹¬å¼§å†…å½¢å¼
            r'ã€(\d{4})å¹´.*?-.*?(\d{4})å¹´',  # å†’é ­å½¢å¼
            r'(\d{4})å¹´.*?-.*?(\d{4})å¹´',  # åŸºæœ¬å½¢å¼
        ]
        
        for i, pattern in enumerate(life_span_patterns):
            life_match = re.search(pattern, text)
            if life_match:
                birth_year = int(life_match.group(1))
                death_year = int(life_match.group(2))
                
                # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼šè¿‘ä¸–ã€œè¿‘ä»£ã®äººç‰©
                if 1800 <= birth_year <= 1950 and 1850 <= death_year <= 2000 and birth_year < death_year:
                    return birth_year, death_year
                else:
                    continue
        
        # å€‹åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¢ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        birth_patterns = [
            r'(\d{4})å¹´\d+æœˆ\d+æ—¥ã€ˆ',  # 1862å¹´5æœˆ22æ—¥ã€ˆ å½¢å¼
            r'ï¼ˆ(\d{4})å¹´.*?æœˆ.*?æ—¥.*?-',  # (1901å¹´2æœˆ17æ—¥ - å½¢å¼
            r'ã€(\d{4})å¹´.*?æœˆ.*?æ—¥',  # ã€1862å¹´5æœˆ22æ—¥ å½¢å¼
        ]
        
        death_patterns = [
            r'-\s*(\d{4})å¹´ã€ˆ.*?ã€‰.*?æœˆ.*?æ—¥',  # - 1957å¹´ã€ˆæ˜­å’Œ32å¹´ã€‰1æœˆ18æ—¥ å½¢å¼
            r'-.*?(\d{4})å¹´.*?æœˆ.*?æ—¥',  # - 1932å¹´3æœˆ24æ—¥ å½¢å¼
        ]
        
        birth_year = self._extract_year_from_patterns(text, birth_patterns)
        death_year = self._extract_year_from_patterns(text, death_patterns)
        
        # æœ€çµ‚å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if birth_year and death_year:
            if 1800 <= birth_year <= 1950 and 1850 <= death_year <= 2000 and birth_year < death_year:
                return birth_year, death_year
        
        return birth_year, death_year
    
    def _extract_year_from_patterns(self, text: str, patterns: List[str]) -> Optional[int]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆã‹ã‚‰å¹´ã‚’æŠ½å‡º"""
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    year_str = match.group(1)
                    year = int(year_str)
                    
                    # å¹´å·å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    if 'æ˜æ²»' in pattern:
                        year = 1867 + year
                    elif 'å¤§æ­£' in pattern:
                        year = 1911 + year
                    elif 'æ˜­å’Œ' in pattern:
                        year = 1925 + year
                    
                    # å¦¥å½“ãªå¹´ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
                    if 1800 <= year <= 2100:
                        return year
                except (ValueError, IndexError):
                    continue
        return None
    
    def enrich_author_info(self, author_id: int, author_name: str) -> bool:
        """æŒ‡å®šä½œè€…ã®æƒ…å ±ã‚’Wikipediaã‹ã‚‰è£œå®Œ"""
        print(f"\nğŸ“ {author_name} (ID: {author_id}) ã®æƒ…å ±ã‚’è£œå®Œä¸­...")
        
        # Wikipediaæƒ…å ±å–å¾—
        wiki_info = self.search_author_wikipedia(author_name)
        
        if not wiki_info:
            print(f"âŒ {author_name} ã®Wikipediaæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            self.stats['failure_count'] += 1
            return False
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
        update_fields = {}
        updates_made = []
        
        # ç”Ÿå¹´æ›´æ–°
        if wiki_info['birth_year']:
            update_fields['birth_year'] = wiki_info['birth_year']
            updates_made.append(f"ç”Ÿå¹´: {wiki_info['birth_year']}å¹´")
            self.stats['birth_year_updated'] += 1
        
        # æ²¡å¹´æ›´æ–°
        if wiki_info['death_year']:
            update_fields['death_year'] = wiki_info['death_year']
            updates_made.append(f"æ²¡å¹´: {wiki_info['death_year']}å¹´")
            self.stats['death_year_updated'] += 1
        
        # Wikipedia URLæ›´æ–°
        if wiki_info['url']:
            update_fields['wikipedia_url'] = wiki_info['url']
            updates_made.append(f"Wikipedia URL")
            self.stats['wikipedia_url_updated'] += 1
        
        if update_fields:
            try:
                # authors ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°ã‚¯ã‚¨ãƒªæ§‹ç¯‰
                set_clause = ', '.join([f"{field} = ?" for field in update_fields.keys()])
                values = list(update_fields.values()) + [author_id]
                
                query = f"""
                UPDATE authors 
                SET {set_clause}
                WHERE author_id = ?
                """
                
                with self.db.get_connection() as conn:
                    cursor = conn.execute(query, values)
                    conn.commit()
                
                print(f"âœ… {author_name} ã®æƒ…å ±ã‚’æ›´æ–°: {', '.join(updates_made)}")
                self.stats['success_count'] += 1
                return True
                
            except Exception as e:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼ ({author_name}): {e}")
                self.stats['failure_count'] += 1
                return False
        else:
            print(f"âš ï¸ {author_name} ã®è¿½åŠ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            self.stats['failure_count'] += 1
            return False
    
    def enrich_all_authors(self) -> Dict:
        """å…¨ä½œè€…ã®æƒ…å ±ã‚’ä¸€æ‹¬è£œå®Œ"""
        print("ğŸŒŸ å…¨ä½œè€…æƒ…å ±ã®ä¸€æ‹¬è£œå®Œã‚’é–‹å§‹ã—ã¾ã™...")
        start_time = time.time()
        
        try:
            # å…¨ä½œè€…å–å¾—
            with self.db.get_connection() as conn:
                cursor = conn.execute("SELECT author_id, author_name FROM authors ORDER BY author_name")
                authors = cursor.fetchall()
            
            if not authors:
                print("âŒ ä½œè€…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return self.stats
            
            self.stats['total_authors'] = len(authors)
            print(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {len(authors)} äººã®ä½œè€…")
            
            # å„ä½œè€…ã«ã¤ã„ã¦å‡¦ç†
            for i, (author_id, author_name) in enumerate(authors, 1):
                print(f"\nğŸ”„ [{i}/{len(authors)}] å‡¦ç†ä¸­...")
                
                # Wikipediaæƒ…å ±ã§è£œå®Œ
                self.enrich_author_info(author_id, author_name)
                
                # APIåˆ¶é™å¯¾ç­–ï¼ˆ1ç§’é–“éš”ï¼‰
                time.sleep(1.0)
            
            # çµ±è¨ˆæƒ…å ±æ›´æ–°
            self.stats['processing_time'] = time.time() - start_time
            
            return self.stats
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['processing_time'] = time.time() - start_time
            return self.stats
    
    def enrich_specific_authors(self, author_names: List[str]) -> Dict:
        """æŒ‡å®šã—ãŸä½œè€…ã®ã¿æƒ…å ±è£œå®Œ"""
        print(f"ğŸ¯ æŒ‡å®šä½œè€…ã®æƒ…å ±è£œå®Œã‚’é–‹å§‹: {', '.join(author_names)}")
        start_time = time.time()
        
        for author_name in author_names:
            try:
                # ä½œè€…IDå–å¾—
                with self.db.get_connection() as conn:
                    cursor = conn.execute(
                        "SELECT author_id, author_name FROM authors WHERE author_name = ?", 
                        (author_name,)
                    )
                    author_data = cursor.fetchone()
                
                if not author_data:
                    print(f"âŒ ä½œè€… '{author_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    self.stats['failure_count'] += 1
                    continue
                
                author_id, db_author_name = author_data
                self.stats['total_authors'] += 1
                
                # Wikipediaæƒ…å ±ã§è£œå®Œ
                self.enrich_author_info(author_id, db_author_name)
                
                # APIåˆ¶é™å¯¾ç­–
                time.sleep(1.0)
                
            except Exception as e:
                print(f"âŒ ä½œè€… '{author_name}' ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                self.stats['failure_count'] += 1
        
        # çµ±è¨ˆæƒ…å ±æ›´æ–°
        self.stats['processing_time'] = time.time() - start_time
        
        return self.stats
    
    def print_statistics(self):
        """å‡¦ç†çµ±è¨ˆã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š Wikipediaä½œè€…æƒ…å ±è£œå®Œ - å‡¦ç†çµæœ")
        print("="*60)
        print(f"å‡¦ç†å¯¾è±¡ä½œè€…æ•°: {self.stats['total_authors']} äºº")
        print(f"æˆåŠŸ: {self.stats['success_count']} äºº")
        print(f"å¤±æ•—: {self.stats['failure_count']} äºº")
        print(f"æˆåŠŸç‡: {self.stats['success_count']/max(1, self.stats['total_authors'])*100:.1f}%")
        print("-"*60)
        print(f"ç”Ÿå¹´è£œå®Œ: {self.stats['birth_year_updated']} ä»¶")
        print(f"æ²¡å¹´è£œå®Œ: {self.stats['death_year_updated']} ä»¶")
        print(f"Wikipedia URLè£œå®Œ: {self.stats['wikipedia_url_updated']} ä»¶")
        print(f"å‡¦ç†æ™‚é–“: {self.stats['processing_time']:.1f} ç§’")
        print("="*60)
    
    def preview_missing_info(self) -> Dict:
        """ä¸è¶³ã—ã¦ã„ã‚‹ä½œè€…æƒ…å ±ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        print("ğŸ” ä¸è¶³ã—ã¦ã„ã‚‹ä½œè€…æƒ…å ±ã‚’ç¢ºèªä¸­...")
        
        query = """
        SELECT 
            author_id, 
            author_name,
            birth_year as author_birth_year,
            death_year as author_death_year,
            wikipedia_url,
            aozora_works_count
        FROM authors 
        WHERE birth_year IS NULL 
           OR death_year IS NULL 
           OR wikipedia_url IS NULL
        ORDER BY aozora_works_count DESC, author_name
        """
        
        try:
            with self.db.get_connection() as conn:
                cursor = conn.execute(query)
                missing_info_authors = cursor.fetchall()
            
            if not missing_info_authors:
                print("âœ… å…¨ã¦ã®ä½œè€…æƒ…å ±ãŒå®Œå…¨ã§ã™ï¼")
                return {'missing_count': 0, 'authors': []}
            
            print(f"ğŸ“‹ æƒ…å ±ä¸è¶³ã®ä½œè€…: {len(missing_info_authors)} äºº")
            print("-"*90)
            print(f"{'ID':<4} {'ä½œè€…å':<20} {'ä½œå“æ•°':<6} {'ç”Ÿå¹´':<8} {'æ²¡å¹´':<8} {'Wikipedia':<10}")
            print("-"*90)
            
            for author_id, name, birth, death, wiki_url, works_count in missing_info_authors:
                birth_str = str(birth) if birth else "ãªã—"
                death_str = str(death) if death else "ãªã—"
                wiki_str = "ã‚ã‚Š" if wiki_url else "ãªã—"
                works_str = str(works_count) if works_count else "0"
                print(f"{author_id:<4} {name:<20} {works_str:<6} {birth_str:<8} {death_str:<8} {wiki_str:<10}")
            
            return {
                'missing_count': len(missing_info_authors),
                'authors': missing_info_authors
            }
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return {'missing_count': 0, 'authors': []}
    
    def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        # DatabaseManagerã«ã¯æ˜ç¤ºçš„ãªcloseãƒ¡ã‚½ãƒƒãƒ‰ãŒãªã„ãŸã‚ã€ãƒ‘ã‚¹
        pass


def enrich_limited_authors(enricher, limit: int) -> Dict:
    """æŒ‡å®šæ•°ã®ä½œè€…ã®æƒ…å ±ã‚’è£œå®Œ"""
    print(f"ğŸ¯ {limit}åé™å®šã§ã®ä½œè€…æƒ…å ±è£œå®Œã‚’é–‹å§‹ã—ã¾ã™...")
    start_time = time.time()
    
    try:
        # æƒ…å ±ä¸è¶³ã®ä½œè€…ã‚’å–å¾—ï¼ˆä½œå“æ•°é †ã€limité©ç”¨ï¼‰
        query = """
        SELECT author_id, author_name 
        FROM authors 
        WHERE birth_year IS NULL 
           OR death_year IS NULL 
           OR wikipedia_url IS NULL
        ORDER BY aozora_works_count DESC, author_name
        LIMIT ?
        """
        
        with enricher.db.get_connection() as conn:
            cursor = conn.execute(query, (limit,))
            authors = cursor.fetchall()
        
        if not authors:
            print("âŒ å‡¦ç†å¯¾è±¡ã®ä½œè€…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return enricher.stats
        
        enricher.stats['total_authors'] = len(authors)
        print(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {len(authors)} äººã®ä½œè€…")
        
        # å„ä½œè€…ã«ã¤ã„ã¦å‡¦ç†
        for i, (author_id, author_name) in enumerate(authors, 1):
            print(f"\nğŸ”„ [{i}/{len(authors)}] å‡¦ç†ä¸­...")
            
            # Wikipediaæƒ…å ±ã§è£œå®Œ
            enricher.enrich_author_info(author_id, author_name)
            
            # APIåˆ¶é™å¯¾ç­–ï¼ˆ1ç§’é–“éš”ï¼‰
            time.sleep(1.0)
        
        # çµ±è¨ˆæƒ…å ±æ›´æ–°
        enricher.stats['processing_time'] = time.time() - start_time
        
        return enricher.stats
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        enricher.stats['processing_time'] = time.time() - start_time
        return enricher.stats

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Wikipediaä½œè€…æƒ…å ±è‡ªå‹•è£œå®Œã‚·ã‚¹ãƒ†ãƒ ')
    parser.add_argument('--limit', type=int, help='å‡¦ç†ã™ã‚‹ä½œè€…æ•°ã®ä¸Šé™')
    parser.add_argument('--specific-authors', type=str, help='ç‰¹å®šä½œè€…åï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿè¡Œã›ãšã«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿')
    
    args = parser.parse_args()
    
    enricher = WikipediaAuthorEnricher()
    
    try:
        # ä¸è¶³æƒ…å ±ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        missing_info = enricher.preview_missing_info()
        
        if missing_info['missing_count'] == 0:
            print("âœ… å‡¦ç†ã¯ä¸è¦ã§ã™")
            return
        
        # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ã®å ´åˆã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿
        if args.dry_run:
            print("ğŸ” ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³: ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ")
            return
        
        # ç‰¹å®šä½œè€…æŒ‡å®šã®å ´åˆ
        if args.specific_authors:
            author_names = [name.strip() for name in args.specific_authors.split(',')]
            print(f"ğŸ¯ ç‰¹å®šä½œè€…ã®å‡¦ç†: {author_names}")
            stats = enricher.enrich_specific_authors(author_names)
            enricher.print_statistics()
            return
        
        # é™å®šå‡¦ç†ã®å ´åˆ
        if args.limit:
            print(f"ğŸ¯ {args.limit}åé™å®šã§å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™")
            stats = enrich_limited_authors(enricher, args.limit)
            enricher.print_statistics()
            return
        
        # é€šå¸¸ã®å…¨ä½œè€…å‡¦ç†
        print(f"\nğŸ¤” {missing_info['missing_count']} äººã®ä½œè€…æƒ…å ±ã‚’è£œå®Œã—ã¾ã™ã‹ï¼Ÿ")
        print("ã“ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
        
        response = input("å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        
        if response in ['y', 'yes']:
            # å…¨ä½œè€…ã®æƒ…å ±è£œå®Œå®Ÿè¡Œ
            stats = enricher.enrich_all_authors()
            enricher.print_statistics()
        else:
            print("âŒ å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        enricher.close()


if __name__ == "__main__":
    main() 