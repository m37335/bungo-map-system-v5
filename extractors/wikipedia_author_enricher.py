#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Wikipediaä½œè€…æƒ…å ±è‡ªå‹•è£œå®Œã‚·ã‚¹ãƒ†ãƒ  v4.0
æ—¢å­˜ã®ä½œè€…ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç”Ÿå¹´ãƒ»æ²¡å¹´ç­‰ã‚’è‡ªå‹•è£œå®Œ
"""

import re
import requests
import wikipedia
from typing import List, Dict, Optional, Tuple
from bs4 import BeautifulSoup
import time
import json
from datetime import datetime
import sys
import os

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.manager import DatabaseManager


class WikipediaAuthorEnricher:
    """Wikipedia ã‹ã‚‰ä½œè€…æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’è£œå®Œ"""
    
    def __init__(self):
        # Wikipediaè¨€èªè¨­å®š
        wikipedia.set_lang("ja")
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'BungoMapBot/4.0 (bungo-map@example.com)'
        })
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        self.db = DatabaseManager()
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_authors': 0,
            'success_count': 0,
            'failure_count': 0,
            'birth_year_updated': 0,
            'death_year_updated': 0,
            'wikipedia_url_updated': 0,
            'processing_time': 0.0
        }
        
    def search_author_wikipedia(self, author_name: str) -> Optional[Dict]:
        """ä½œè€…ã®Wikipediaæƒ…å ±ã‚’è©³ç´°æ¤œç´¢"""
        try:
            print(f"ğŸ” {author_name} ã®æƒ…å ±ã‚’æ¤œç´¢ä¸­...")
            
            # Wikipediaæ¤œç´¢
            page = wikipedia.page(author_name)
            
            # åŸºæœ¬æƒ…å ±æŠ½å‡º
            extract = page.summary
            birth_year, death_year = self._extract_life_years(extract, page.content)
            
            return {
                'title': page.title,
                'url': page.url,
                'extract': extract[:500],  # è¦ç´„ï¼ˆ500æ–‡å­—ï¼‰
                'content': page.content,
                'birth_year': birth_year,
                'death_year': death_year
            }
            
        except wikipedia.exceptions.DisambiguationError as e:
            # æ›–æ˜§ã•å›é¿ãƒšãƒ¼ã‚¸ã®å ´åˆã€æœ€åˆã®å€™è£œã‚’è©¦ã™
            try:
                page = wikipedia.page(e.options[0])
                extract = page.summary
                birth_year, death_year = self._extract_life_years(extract, page.content)
                
                return {
                    'title': page.title,
                    'url': page.url,
                    'extract': extract[:500],
                    'content': page.content,
                    'birth_year': birth_year,
                    'death_year': death_year
                }
            except Exception as e2:
                print(f"âš ï¸ æ›–æ˜§ã•å›é¿ã‚¨ãƒ©ãƒ¼ ({author_name}): {e2}")
                
        except wikipedia.exceptions.PageError:
            print(f"âš ï¸ ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {author_name}")
            
        except Exception as e:
            print(f"âš ï¸ Wikipediaæ¤œç´¢ã‚¨ãƒ©ãƒ¼ ({author_name}): {e}")
            
        return None
    
    def _extract_life_years(self, summary: str, content: str) -> Tuple[Optional[int], Optional[int]]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”Ÿå¹´ãƒ»æ²¡å¹´ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # ã‚ˆã‚Šå¤šæ§˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ
        text = summary + " " + content[:2000]  # æœ€åˆã®éƒ¨åˆ†ã®ã¿ä½¿ç”¨
        
        # (å¹´å· - å¹´å·) ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æœ€å„ªå…ˆã§æ¢ã™
        life_span_patterns = [
            r'ã€(\d{4})å¹´ã€ˆ.*?ã€‰.*?-.*?(\d{4})å¹´ã€ˆ.*?ã€‰',  # ã€1909å¹´ã€ˆæ˜æ²»42å¹´ã€‰6æœˆ19æ—¥ - 1948å¹´ã€ˆæ˜­å’Œ23å¹´ã€‰ å½¢å¼
            r'ï¼ˆ(\d{4})å¹´.*?-.*?(\d{4})å¹´.*?ï¼‰',
            r'(\d{4})å¹´.*?-.*?(\d{4})å¹´',
        ]
        
        for pattern in life_span_patterns:
            life_match = re.search(pattern, text)
            if life_match:
                birth_year = int(life_match.group(1))
                death_year = int(life_match.group(2))
                return birth_year, death_year
        
        # å€‹åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¢ã™
        birth_patterns = [
            r'ï¼ˆ(\d{4})å¹´.*?æœˆ.*?æ—¥.*?-',  # (1901å¹´2æœˆ17æ—¥ - å½¢å¼
            r'ï¼ˆ(\d{4})å¹´.*?-',  # (1901å¹´ - å½¢å¼
            r'(\d{4})å¹´.*?æœˆ.*?æ—¥.*?ç”Ÿ',
            r'(\d{4})å¹´.*?ç”Ÿã¾ã‚Œ',
            r'ç”Ÿå¹´.*?(\d{4})å¹´',
            r'(\d{4})å¹´.*?èª•ç”Ÿ',
            r'æ˜æ²»(\d+)å¹´.*?ç”Ÿ',  # æ˜æ²»å¹´å·
            r'å¤§æ­£(\d+)å¹´.*?ç”Ÿ',  # å¤§æ­£å¹´å·
            r'æ˜­å’Œ(\d+)å¹´.*?ç”Ÿ',  # æ˜­å’Œå¹´å·
        ]
        
        death_patterns = [
            r'-.*?(\d{4})å¹´.*?æœˆ.*?æ—¥.*?ï¼‰',  # - 1932å¹´3æœˆ24æ—¥ï¼‰ å½¢å¼
            r'-.*?(\d{4})å¹´.*?ï¼‰',  # - 1932å¹´ï¼‰ å½¢å¼
            r'(\d{4})å¹´.*?æœˆ.*?æ—¥.*?æ²¡',
            r'(\d{4})å¹´.*?æ­»å»',
            r'æ²¡å¹´.*?(\d{4})å¹´',
            r'(\d{4})å¹´.*?é€å»',
            r'æ˜­å’Œ(\d+)å¹´.*?æ²¡',  # æ˜­å’Œå¹´å·
            r'å¤§æ­£(\d+)å¹´.*?æ²¡',  # å¤§æ­£å¹´å·
            r'æ˜æ²»(\d+)å¹´.*?æ²¡',  # æ˜æ²»å¹´å·
        ]
        
        birth_year = self._extract_year_from_patterns(text, birth_patterns)
        death_year = self._extract_year_from_patterns(text, death_patterns)
        
        return birth_year, death_year
    
    def _extract_year_from_patterns(self, text: str, patterns: List[str]) -> Optional[int]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆã‹ã‚‰å¹´ã‚’æŠ½å‡º"""
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    year_str = match.group(1)
                    year = int(year_str)
                    
                    # å¹´å·å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    if 'æ˜æ²»' in pattern:
                        year = 1867 + year
                    elif 'å¤§æ­£' in pattern:
                        year = 1911 + year
                    elif 'æ˜­å’Œ' in pattern:
                        year = 1925 + year
                    
                    # å¦¥å½“ãªå¹´ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
                    if 1800 <= year <= 2100:
                        return year
                except (ValueError, IndexError):
                    continue
        return None
    
    def enrich_author_info(self, author_id: int, author_name: str) -> bool:
        """æŒ‡å®šä½œè€…ã®æƒ…å ±ã‚’Wikipediaã‹ã‚‰è£œå®Œ"""
        print(f"\nğŸ“ {author_name} (ID: {author_id}) ã®æƒ…å ±ã‚’è£œå®Œä¸­...")
        
        # Wikipediaæƒ…å ±å–å¾—
        wiki_info = self.search_author_wikipedia(author_name)
        
        if not wiki_info:
            print(f"âŒ {author_name} ã®Wikipediaæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            self.stats['failure_count'] += 1
            return False
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
        update_fields = {}
        updates_made = []
        
        # ç”Ÿå¹´æ›´æ–°
        if wiki_info['birth_year']:
            update_fields['birth_year'] = wiki_info['birth_year']
            updates_made.append(f"ç”Ÿå¹´: {wiki_info['birth_year']}å¹´")
            self.stats['birth_year_updated'] += 1
        
        # æ²¡å¹´æ›´æ–°
        if wiki_info['death_year']:
            update_fields['death_year'] = wiki_info['death_year']
            updates_made.append(f"æ²¡å¹´: {wiki_info['death_year']}å¹´")
            self.stats['death_year_updated'] += 1
        
        # Wikipedia URLæ›´æ–°
        if wiki_info['url']:
            update_fields['wikipedia_url'] = wiki_info['url']
            updates_made.append(f"Wikipedia URL")
            self.stats['wikipedia_url_updated'] += 1
        
        if update_fields:
            try:
                # authors ãƒ†ãƒ¼ãƒ–ãƒ«æ›´æ–°ã‚¯ã‚¨ãƒªæ§‹ç¯‰
                set_clause = ', '.join([f"{field} = ?" for field in update_fields.keys()])
                values = list(update_fields.values()) + [author_id]
                
                query = f"""
                UPDATE authors 
                SET {set_clause}
                WHERE author_id = ?
                """
                
                with self.db.get_connection() as conn:
                    cursor = conn.execute(query, values)
                    conn.commit()
                
                print(f"âœ… {author_name} ã®æƒ…å ±ã‚’æ›´æ–°: {', '.join(updates_made)}")
                self.stats['success_count'] += 1
                return True
                
            except Exception as e:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼ ({author_name}): {e}")
                self.stats['failure_count'] += 1
                return False
        else:
            print(f"âš ï¸ {author_name} ã®è¿½åŠ æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            self.stats['failure_count'] += 1
            return False
    
    def enrich_all_authors(self) -> Dict:
        """å…¨ä½œè€…ã®æƒ…å ±ã‚’ä¸€æ‹¬è£œå®Œ"""
        print("ğŸŒŸ å…¨ä½œè€…æƒ…å ±ã®ä¸€æ‹¬è£œå®Œã‚’é–‹å§‹ã—ã¾ã™...")
        start_time = time.time()
        
        try:
            # å…¨ä½œè€…å–å¾—
            with self.db.get_connection() as conn:
                cursor = conn.execute("SELECT author_id, author_name FROM authors ORDER BY author_name")
                authors = cursor.fetchall()
            
            if not authors:
                print("âŒ ä½œè€…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return self.stats
            
            self.stats['total_authors'] = len(authors)
            print(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {len(authors)} äººã®ä½œè€…")
            
            # å„ä½œè€…ã«ã¤ã„ã¦å‡¦ç†
            for i, (author_id, author_name) in enumerate(authors, 1):
                print(f"\nğŸ”„ [{i}/{len(authors)}] å‡¦ç†ä¸­...")
                
                # Wikipediaæƒ…å ±ã§è£œå®Œ
                self.enrich_author_info(author_id, author_name)
                
                # APIåˆ¶é™å¯¾ç­–ï¼ˆ1ç§’é–“éš”ï¼‰
                time.sleep(1.0)
            
            # çµ±è¨ˆæƒ…å ±æ›´æ–°
            self.stats['processing_time'] = time.time() - start_time
            
            return self.stats
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['processing_time'] = time.time() - start_time
            return self.stats
    
    def enrich_specific_authors(self, author_names: List[str]) -> Dict:
        """æŒ‡å®šã—ãŸä½œè€…ã®ã¿æƒ…å ±è£œå®Œ"""
        print(f"ğŸ¯ æŒ‡å®šä½œè€…ã®æƒ…å ±è£œå®Œã‚’é–‹å§‹: {', '.join(author_names)}")
        start_time = time.time()
        
        for author_name in author_names:
            try:
                # ä½œè€…IDå–å¾—
                with self.db.get_connection() as conn:
                    cursor = conn.execute(
                        "SELECT author_id, author_name FROM authors WHERE author_name = ?", 
                        (author_name,)
                    )
                    author_data = cursor.fetchone()
                
                if not author_data:
                    print(f"âŒ ä½œè€… '{author_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    self.stats['failure_count'] += 1
                    continue
                
                author_id, db_author_name = author_data
                self.stats['total_authors'] += 1
                
                # Wikipediaæƒ…å ±ã§è£œå®Œ
                self.enrich_author_info(author_id, db_author_name)
                
                # APIåˆ¶é™å¯¾ç­–
                time.sleep(1.0)
                
            except Exception as e:
                print(f"âŒ ä½œè€… '{author_name}' ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                self.stats['failure_count'] += 1
        
        # çµ±è¨ˆæƒ…å ±æ›´æ–°
        self.stats['processing_time'] = time.time() - start_time
        
        return self.stats
    
    def print_statistics(self):
        """å‡¦ç†çµ±è¨ˆã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š Wikipediaä½œè€…æƒ…å ±è£œå®Œ - å‡¦ç†çµæœ")
        print("="*60)
        print(f"å‡¦ç†å¯¾è±¡ä½œè€…æ•°: {self.stats['total_authors']} äºº")
        print(f"æˆåŠŸ: {self.stats['success_count']} äºº")
        print(f"å¤±æ•—: {self.stats['failure_count']} äºº")
        print(f"æˆåŠŸç‡: {self.stats['success_count']/max(1, self.stats['total_authors'])*100:.1f}%")
        print("-"*60)
        print(f"ç”Ÿå¹´è£œå®Œ: {self.stats['birth_year_updated']} ä»¶")
        print(f"æ²¡å¹´è£œå®Œ: {self.stats['death_year_updated']} ä»¶")
        print(f"Wikipedia URLè£œå®Œ: {self.stats['wikipedia_url_updated']} ä»¶")
        print(f"å‡¦ç†æ™‚é–“: {self.stats['processing_time']:.1f} ç§’")
        print("="*60)
    
    def preview_missing_info(self) -> Dict:
        """ä¸è¶³ã—ã¦ã„ã‚‹ä½œè€…æƒ…å ±ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        print("ğŸ” ä¸è¶³ã—ã¦ã„ã‚‹ä½œè€…æƒ…å ±ã‚’ç¢ºèªä¸­...")
        
        query = """
        SELECT 
            author_id, 
            author_name,
            birth_year as author_birth_year,
            death_year as author_death_year,
            wikipedia_url
        FROM authors 
        WHERE birth_year IS NULL 
           OR death_year IS NULL 
           OR wikipedia_url IS NULL
        ORDER BY author_name
        """
        
        try:
            with self.db.get_connection() as conn:
                cursor = conn.execute(query)
                missing_info_authors = cursor.fetchall()
            
            if not missing_info_authors:
                print("âœ… å…¨ã¦ã®ä½œè€…æƒ…å ±ãŒå®Œå…¨ã§ã™ï¼")
                return {'missing_count': 0, 'authors': []}
            
            print(f"ğŸ“‹ æƒ…å ±ä¸è¶³ã®ä½œè€…: {len(missing_info_authors)} äºº")
            print("-"*80)
            print(f"{'ID':<4} {'ä½œè€…å':<20} {'ç”Ÿå¹´':<8} {'æ²¡å¹´':<8} {'Wikipedia':<10}")
            print("-"*80)
            
            for author_id, name, birth, death, wiki_url in missing_info_authors:
                birth_str = str(birth) if birth else "ãªã—"
                death_str = str(death) if death else "ãªã—"
                wiki_str = "ã‚ã‚Š" if wiki_url else "ãªã—"
                print(f"{author_id:<4} {name:<20} {birth_str:<8} {death_str:<8} {wiki_str:<10}")
            
            return {
                'missing_count': len(missing_info_authors),
                'authors': missing_info_authors
            }
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return {'missing_count': 0, 'authors': []}
    
    def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        # DatabaseManagerã«ã¯æ˜ç¤ºçš„ãªcloseãƒ¡ã‚½ãƒƒãƒ‰ãŒãªã„ãŸã‚ã€ãƒ‘ã‚¹
        pass


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    enricher = WikipediaAuthorEnricher()
    
    try:
        # ä¸è¶³æƒ…å ±ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        missing_info = enricher.preview_missing_info()
        
        if missing_info['missing_count'] == 0:
            print("âœ… å‡¦ç†ã¯ä¸è¦ã§ã™")
            return
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª
        print(f"\nğŸ¤” {missing_info['missing_count']} äººã®ä½œè€…æƒ…å ±ã‚’è£œå®Œã—ã¾ã™ã‹ï¼Ÿ")
        print("ã“ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
        
        response = input("å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        
        if response in ['y', 'yes']:
            # å…¨ä½œè€…ã®æƒ…å ±è£œå®Œå®Ÿè¡Œ
            stats = enricher.enrich_all_authors()
            enricher.print_statistics()
        else:
            print("âŒ å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    finally:
        enricher.close()


if __name__ == "__main__":
    main() 