#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡è±ªã‚†ã‹ã‚Šåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  v4.0 - ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿®æ­£ãƒ»è£œå®Œä½œæ¥­ã‚’ä¸€æ‹¬å®Ÿè¡Œ

æ©Ÿèƒ½:
1. sentence_placesãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œè€…ãƒ»ä½œå“æƒ…å ±è£œå®Œ
2. worksãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®Œï¼ˆå‡ºç‰ˆå¹´ç­‰ï¼‰
3. sentence_placesãƒ†ãƒ¼ãƒ–ãƒ«ã®work_publication_yearè£œå®Œ
4. matched_textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ä¿®æ­£ï¼ˆåœ°åã®ã¿â†’æ–‡å…¨ä½“ï¼‰

ä½¿ç”¨ä¾‹:
    python3 maintenance_pipeline.py --all
    python3 maintenance_pipeline.py --enrich-sentence-places
    python3 maintenance_pipeline.py --enrich-works-metadata
    python3 maintenance_pipeline.py --update-publication-year
    python3 maintenance_pipeline.py --fix-matched-text
"""

import sys
import os
import argparse
import sqlite3
import subprocess
from datetime import datetime
from typing import Dict, Any

# ãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from database.sentence_places_enricher import SentencePlacesEnricher
from ..aozora.aozora_metadata_extractor import AozoraMetadataExtractor

class MaintenancePipeline:
    """ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå™¨"""
    
    def __init__(self):
        print("ğŸ”§ æ–‡è±ªã‚†ã‹ã‚Šåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...")
        self.db_path = os.path.join(parent_dir, 'data', 'bungo_map.db')
        self.enricher = SentencePlacesEnricher()
        self.metadata_extractor = AozoraMetadataExtractor()
        print("âœ… ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def run_all_maintenance(self) -> Dict[str, Any]:
        """å…¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­ã‚’ä¸€æ‹¬å®Ÿè¡Œ"""
        start_time = datetime.now()
        print(f"\nğŸš€ å…¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­é–‹å§‹ - {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        results = {
            'start_time': start_time,
            'success': False,
            'steps_completed': [],
            'steps_failed': [],
            'enriched_sentence_places': 0,
            'enriched_works': 0,
            'updated_publication_years': 0,
            'fixed_matched_texts': 0,
            'errors': []
        }
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: sentence_placesãƒ†ãƒ¼ãƒ–ãƒ«è£œå®Œ
            print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—1: sentence_placesãƒ†ãƒ¼ãƒ–ãƒ«ä½œè€…ãƒ»ä½œå“æƒ…å ±è£œå®Œ...")
            step1_result = self.enrich_sentence_places()
            if step1_result['success']:
                results['enriched_sentence_places'] = step1_result['enriched_count']
                results['steps_completed'].append('sentence_places_enrichment')
                print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: {step1_result['enriched_count']}ä»¶è£œå®Œ")
            else:
                results['steps_failed'].append('sentence_places_enrichment')
                results['errors'].extend(step1_result['errors'])
                print(f"âŒ ã‚¹ãƒ†ãƒƒãƒ—1å¤±æ•—: {step1_result['errors']}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: worksãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®Œ
            print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—2: worksãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®Œ...")
            step2_result = self.enrich_works_metadata()
            if step2_result['success']:
                results['enriched_works'] = step2_result['enriched_count']
                results['steps_completed'].append('works_metadata_enrichment')
                print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: {step2_result['enriched_count']}ä»¶è£œå®Œ")
            else:
                results['steps_failed'].append('works_metadata_enrichment')
                results['errors'].extend(step2_result['errors'])
                print(f"âŒ ã‚¹ãƒ†ãƒƒãƒ—2å¤±æ•—: {step2_result['errors']}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: work_publication_yearæ›´æ–°
            print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—3: sentence_placesã®work_publication_yearè£œå®Œ...")
            step3_result = self.update_publication_years()
            if step3_result['success']:
                results['updated_publication_years'] = step3_result['updated_count']
                results['steps_completed'].append('publication_year_update')
                print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†: {step3_result['updated_count']}ä»¶æ›´æ–°")
            else:
                results['steps_failed'].append('publication_year_update')
                results['errors'].extend(step3_result['errors'])
                print(f"âŒ ã‚¹ãƒ†ãƒƒãƒ—3å¤±æ•—: {step3_result['errors']}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: matched_textä¿®æ­£
            print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—4: matched_textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¿®æ­£ï¼ˆåœ°åã®ã¿â†’æ–‡å…¨ä½“ï¼‰...")
            step4_result = self.fix_matched_text()
            if step4_result['success']:
                results['fixed_matched_texts'] = step4_result['fixed_count']
                results['steps_completed'].append('matched_text_fix')
                print(f"âœ… ã‚¹ãƒ†ãƒƒãƒ—4å®Œäº†: {step4_result['fixed_count']}ä»¶ä¿®æ­£")
            else:
                results['steps_failed'].append('matched_text_fix')
                results['errors'].extend(step4_result['errors'])
                print(f"âŒ ã‚¹ãƒ†ãƒƒãƒ—4å¤±æ•—: {step4_result['errors']}")
            
            results['success'] = len(results['steps_failed']) == 0
            
        except Exception as e:
            print(f"âŒ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            results['errors'].append(str(e))
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        end_time = datetime.now()
        results['end_time'] = end_time
        results['duration'] = (end_time - start_time).total_seconds()
        
        self._print_report(results)
        return results
    
    def enrich_sentence_places(self) -> Dict[str, Any]:
        """sentence_placesãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œè€…ãƒ»ä½œå“æƒ…å ±è£œå®Œ"""
        try:
            result = self.enricher.run_full_enrichment()
            return {
                'success': True,
                'enriched_count': result.get('enriched_count', 0),
                'errors': []
            }
        except Exception as e:
            return {
                'success': False,
                'enriched_count': 0,
                'errors': [str(e)]
            }
    
    def enrich_works_metadata(self) -> Dict[str, Any]:
        """worksãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®Œ"""
        try:
            # enrich_works_metadata.pyã‚’å®Ÿè¡Œ
            result = subprocess.run([
                'python3', 'enrich_works_metadata.py'
            ], capture_output=True, text=True, cwd=current_dir)
            
            if result.returncode == 0:
                # æˆåŠŸæ™‚ã®å‡¦ç†ä»¶æ•°ã‚’å‡ºåŠ›ã‹ã‚‰æŠ½å‡º
                output_lines = result.stdout.split('\n')
                enriched_count = 0
                for line in output_lines:
                    if 'ä»¶å‡¦ç†å®Œäº†' in line:
                        try:
                            enriched_count = int(line.split('ä»¶å‡¦ç†å®Œäº†')[0].split()[-1])
                        except:
                            pass
                
                return {
                    'success': True,
                    'enriched_count': enriched_count,
                    'errors': []
                }
            else:
                return {
                    'success': False,
                    'enriched_count': 0,
                    'errors': [result.stderr]
                }
        except Exception as e:
            return {
                'success': False,
                'enriched_count': 0,
                'errors': [str(e)]
            }
    
    def update_publication_years(self) -> Dict[str, Any]:
        """sentence_placesã®work_publication_yearè£œå®Œ"""
        try:
            # update_work_publication_year.pyã‚’å®Ÿè¡Œ
            result = subprocess.run([
                'python3', 'update_work_publication_year.py'
            ], capture_output=True, text=True, cwd=current_dir)
            
            if result.returncode == 0:
                # æˆåŠŸæ™‚ã®å‡¦ç†ä»¶æ•°ã‚’å‡ºåŠ›ã‹ã‚‰æŠ½å‡º
                output_lines = result.stdout.split('\n')
                updated_count = 0
                for line in output_lines:
                    if 'ä»¶æ›´æ–°' in line:
                        try:
                            updated_count = int(line.split('ä»¶æ›´æ–°')[0].split()[-1])
                        except:
                            pass
                
                return {
                    'success': True,
                    'updated_count': updated_count,
                    'errors': []
                }
            else:
                return {
                    'success': False,
                    'updated_count': 0,
                    'errors': [result.stderr]
                }
        except Exception as e:
            return {
                'success': False,
                'updated_count': 0,
                'errors': [str(e)]
            }
    
    def fix_matched_text(self) -> Dict[str, Any]:
        """matched_textãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ä¿®æ­£ï¼ˆåœ°åã®ã¿â†’æ–‡å…¨ä½“ï¼‰"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ä¿®æ­£å‰ã®çŠ¶æ…‹ç¢ºèª
            cursor.execute("SELECT COUNT(*) FROM sentence_places")
            total_count = cursor.fetchone()[0]
            
            # matched_textã‚’å¯¾å¿œã™ã‚‹sentence_textã§æ›´æ–°
            cursor.execute("""
                UPDATE sentence_places 
                SET matched_text = (
                    SELECT sentence_text 
                    FROM sentences 
                    WHERE sentences.sentence_id = sentence_places.sentence_id
                )
            """)
            
            fixed_count = cursor.rowcount
            conn.commit()
            conn.close()
            
            return {
                'success': True,
                'fixed_count': fixed_count,
                'errors': []
            }
        except Exception as e:
            return {
                'success': False,
                'fixed_count': 0,
                'errors': [str(e)]
            }
    
    def get_database_status(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ç¢ºèª"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            status = {}
            
            # åŸºæœ¬çµ±è¨ˆ
            cursor.execute("SELECT COUNT(*) FROM authors")
            status['total_authors'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM works")
            status['total_works'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM sentences")
            status['total_sentences'] = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM sentence_places")
            status['total_sentence_places'] = cursor.fetchone()[0]
            
            # sentence_placesã®è£œå®ŒçŠ¶æ³
            cursor.execute("SELECT COUNT(*) FROM sentence_places WHERE author_name IS NOT NULL")
            status['enriched_sentence_places'] = cursor.fetchone()[0]
            
            # worksã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®ŒçŠ¶æ³
            cursor.execute("SELECT COUNT(*) FROM works WHERE publication_year IS NOT NULL")
            status['works_with_publication_year'] = cursor.fetchone()[0]
            
            # matched_textã®çŠ¶æ³ï¼ˆã‚µãƒ³ãƒ—ãƒ«ç¢ºèªï¼‰
            cursor.execute("SELECT matched_text, place_name_only FROM sentence_places LIMIT 1")
            sample = cursor.fetchone()
            if sample:
                status['matched_text_fixed'] = sample[0] != sample[1]
            else:
                status['matched_text_fixed'] = False
            
            conn.close()
            return status
            
        except Exception as e:
            return {'error': str(e)}
    
    def _print_report(self, results: Dict[str, Any]):
        """ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"""
        print(f"\nğŸ‰ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 80)
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {results['duration']:.1f}ç§’")
        print(f"ğŸ† ç·åˆçµæœ: {'æˆåŠŸ' if results['success'] else 'å¤±æ•—'}")
        print(f"âœ… æˆåŠŸã‚¹ãƒ†ãƒƒãƒ—: {len(results['steps_completed'])}ä»¶")
        print(f"âŒ å¤±æ•—ã‚¹ãƒ†ãƒƒãƒ—: {len(results['steps_failed'])}ä»¶")
        
        print(f"\nğŸ“Š å‡¦ç†çµæœ:")
        print(f"  ğŸ“ sentence_placesè£œå®Œ: {results['enriched_sentence_places']}ä»¶")
        print(f"  ğŸ“š worksãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®Œ: {results['enriched_works']}ä»¶")
        print(f"  ğŸ“… å‡ºç‰ˆå¹´æ›´æ–°: {results['updated_publication_years']}ä»¶")
        print(f"  ğŸ”§ matched_textä¿®æ­£: {results['fixed_matched_texts']}ä»¶")
        
        if results['steps_completed']:
            print(f"\nâœ… æˆåŠŸã‚¹ãƒ†ãƒƒãƒ—:")
            for step in results['steps_completed']:
                print(f"  - {step}")
        
        if results['steps_failed']:
            print(f"\nâŒ å¤±æ•—ã‚¹ãƒ†ãƒƒãƒ—:")
            for step in results['steps_failed']:
                print(f"  - {step}")
        
        if results['errors']:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {len(results['errors'])}ä»¶")
            for error in results['errors']:
                print(f"  - {error}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='æ–‡è±ªã‚†ã‹ã‚Šåœ°å›³ã‚·ã‚¹ãƒ†ãƒ  v4.0 - ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å…¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­å®Ÿè¡Œ
  python3 maintenance_pipeline.py --all
  
  # å€‹åˆ¥ä½œæ¥­å®Ÿè¡Œ
  python3 maintenance_pipeline.py --enrich-sentence-places
  python3 maintenance_pipeline.py --enrich-works-metadata
  python3 maintenance_pipeline.py --update-publication-year
  python3 maintenance_pipeline.py --fix-matched-text
  
  # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ç¢ºèª
  python3 maintenance_pipeline.py --status
        """
    )
    
    parser.add_argument('--all', action='store_true', help='å…¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­ã‚’å®Ÿè¡Œ')
    parser.add_argument('--enrich-sentence-places', action='store_true', help='sentence_placesè£œå®Œã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--enrich-works-metadata', action='store_true', help='worksãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®Œã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--update-publication-year', action='store_true', help='å‡ºç‰ˆå¹´æ›´æ–°ã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--fix-matched-text', action='store_true', help='matched_textä¿®æ­£ã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--status', action='store_true', help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ç¢ºèªã®ã¿')
    
    args = parser.parse_args()
    
    pipeline = MaintenancePipeline()
    
    if args.status:
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ç¢ºèª")
        print("=" * 60)
        status = pipeline.get_database_status()
        
        if 'error' in status:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {status['error']}")
        else:
            print(f"ğŸ‘¤ ä½œè€…æ•°: {status['total_authors']:,}ä»¶")
            print(f"ğŸ“š ä½œå“æ•°: {status['total_works']:,}ä»¶")
            print(f"ğŸ“ ã‚»ãƒ³ãƒ†ãƒ³ã‚¹æ•°: {status['total_sentences']:,}ä»¶")
            print(f"ğŸ—ºï¸ åœ°åé–¢é€£æ•°: {status['total_sentence_places']:,}ä»¶")
            print(f"âœ… sentence_placesè£œå®Œæ¸ˆã¿: {status['enriched_sentence_places']:,}ä»¶")
            print(f"ğŸ“… å‡ºç‰ˆå¹´ã‚ã‚Šä½œå“: {status['works_with_publication_year']:,}ä»¶")
            print(f"ğŸ”§ matched_textä¿®æ­£æ¸ˆã¿: {'ã¯ã„' if status['matched_text_fixed'] else 'ã„ã„ãˆ'}")
        
    elif args.all:
        pipeline.run_all_maintenance()
        
    elif args.enrich_sentence_places:
        print("ğŸ”„ sentence_placesè£œå®Œå®Ÿè¡Œ...")
        result = pipeline.enrich_sentence_places()
        if result['success']:
            print(f"âœ… å®Œäº†: {result['enriched_count']}ä»¶è£œå®Œ")
        else:
            print(f"âŒ å¤±æ•—: {result['errors']}")
            
    elif args.enrich_works_metadata:
        print("ğŸ”„ worksãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è£œå®Œå®Ÿè¡Œ...")
        result = pipeline.enrich_works_metadata()
        if result['success']:
            print(f"âœ… å®Œäº†: {result['enriched_count']}ä»¶è£œå®Œ")
        else:
            print(f"âŒ å¤±æ•—: {result['errors']}")
            
    elif args.update_publication_year:
        print("ğŸ”„ å‡ºç‰ˆå¹´æ›´æ–°å®Ÿè¡Œ...")
        result = pipeline.update_publication_years()
        if result['success']:
            print(f"âœ… å®Œäº†: {result['updated_count']}ä»¶æ›´æ–°")
        else:
            print(f"âŒ å¤±æ•—: {result['errors']}")
            
    elif args.fix_matched_text:
        print("ğŸ”„ matched_textä¿®æ­£å®Ÿè¡Œ...")
        result = pipeline.fix_matched_text()
        if result['success']:
            print(f"âœ… å®Œäº†: {result['fixed_count']}ä»¶ä¿®æ­£")
        else:
            print(f"âŒ å¤±æ•—: {result['errors']}")
            
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 