#!/usr/bin/env python3
"""
é’ç©ºæ–‡åº«ä½œå®¶æƒ…å ±ã®å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š
1. å…¨ä½œå®¶æƒ…å ±ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆ1,331åï¼‰
2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¸€æ‹¬ä¿å­˜
3. è©³ç´°çµ±è¨ˆã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import sys
import os
import json
from datetime import datetime
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from extractors.author_list_scraper import AuthorListScraper
from database.models import Author
from database.config import SessionLocal, init_db
from database.crud import AuthorCRUD

def main():
    print("ğŸš€ é’ç©ºæ–‡åº«å…¨ä½œå®¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—...")
        init_db()
        session = SessionLocal()
        author_crud = AuthorCRUD(session)
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        existing_count = author_crud.get_total_authors()
        if existing_count > 0:
            print(f"âš ï¸  æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {existing_count}åï¼ˆä¸Šæ›¸ãæ›´æ–°ã•ã‚Œã¾ã™ï¼‰")
        
        # å…¨ä½œå®¶æƒ…å ±å–å¾—
        print("\nğŸ“š å…¨ä½œå®¶æƒ…å ±ã‚’å–å¾—ä¸­...")
        scraper = AuthorListScraper(rate_limit=0.5)  # å°‘ã—é«˜é€ŸåŒ–
        authors = scraper.fetch_all_authors()
        
        if not authors:
            print("âŒ ä½œå®¶æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        print(f"âœ… {len(authors)}åã®ä½œå®¶æƒ…å ±ã‚’å–å¾—å®Œäº†")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€æ‹¬ä¿å­˜
        print(f"\nğŸ’¾ {len(authors)}åã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ä¸­...")
        start_time = datetime.now()
        
        saved_count = 0
        updated_count = 0
        error_count = 0
        
        for i, author_info in enumerate(authors, 1):
            try:
                author_data = {
                    'author_name': author_info.name,
                    'author_name_kana': author_info.name_reading,
                    'aozora_author_url': author_info.author_url,
                    'copyright_status': author_info.copyright_status,
                    'aozora_works_count': author_info.works_count,
                    'alias_info': author_info.alias_info,
                    'section': author_info.section,
                    'source_system': 'aozora_scraper_v1.0',
                    'verification_status': 'auto_scraped'
                }
                
                # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
                existing = session.query(Author).filter(
                    Author.author_name == author_info.name
                ).first()
                
                if existing:
                    updated_count += 1
                else:
                    saved_count += 1
                
                result = author_crud.create_author(author_data)
                
                # é€²æ—è¡¨ç¤º
                if i % 100 == 0:
                    print(f"   é€²æ—: {i}/{len(authors)} ({i/len(authors)*100:.1f}%)")
                    
            except Exception as e:
                error_count += 1
                if error_count <= 5:  # æœ€åˆã®5ä»¶ã ã‘ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
                    print(f"âš ï¸  ä¿å­˜ã‚¨ãƒ©ãƒ¼ ({author_info.name}): {e}")
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº† ({processing_time:.1f}ç§’)")
        print(f"   æ–°è¦ä¿å­˜: {saved_count}å")
        print(f"   æ›´æ–°: {updated_count}å")
        print(f"   ã‚¨ãƒ©ãƒ¼: {error_count}å")
        
        # è©³ç´°çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 40)
        
        total_authors = author_crud.get_total_authors()
        total_works = author_crud.get_total_works_count()
        
        print(f"ç·ä½œå®¶æ•°: {total_authors:,}å")
        print(f"ç·ä½œå“æ•°: {total_works:,}ä½œå“")
        print(f"å¹³å‡ä½œå“æ•°: {total_works/total_authors:.1f}ä½œå“/ä½œå®¶")
        
        # è‘—ä½œæ¨©åˆ¥çµ±è¨ˆ
        copyright_stats = author_crud.get_copyright_statistics()
        print(f"\nğŸ“ˆ è‘—ä½œæ¨©åˆ¥çµ±è¨ˆ:")
        for status, count in copyright_stats.items():
            percentage = count / total_authors * 100
            print(f"  {status}: {count:,}å ({percentage:.1f}%)")
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥çµ±è¨ˆ
        section_stats = author_crud.get_section_statistics()
        print(f"\nğŸ“š ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥çµ±è¨ˆ:")
        for section, count in sorted(section_stats.items()):
            print(f"  {section}: {count:,}å")
        
        # ä½œå“æ•°ä¸Šä½ä½œå®¶
        print(f"\nğŸ† ä½œå“æ•°ä¸Šä½10å:")
        top_authors = author_crud.get_top_authors_by_works(10)
        for i, author in enumerate(top_authors, 1):
            print(f"  {i:2}. {author.author_name}: {author.aozora_works_count:,}ä½œå“")
        
        # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        print(f"\nğŸ” æ¤œç´¢ãƒ†ã‚¹ãƒˆ:")
        test_keywords = ["å¤ç›®", "èŠ¥å·", "å¤ªå®°", "å®®æ²¢"]
        for keyword in test_keywords:
            results = author_crud.search_authors(keyword, limit=3)
            print(f"  '{keyword}': {len(results)}ä»¶")
            for author in results[:2]:  # æœ€åˆã®2ä»¶è¡¨ç¤º
                print(f"    - {author.author_name}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        print(f"\nğŸ“¤ å…¨ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ...")
        all_authors = author_crud.get_all_authors()
        
        export_data = []
        for author in all_authors:
            export_data.append({
                'author_id': author.author_id,
                'author_name': author.author_name,
                'author_name_kana': author.author_name_kana,
                'aozora_author_url': author.aozora_author_url,
                'copyright_status': author.copyright_status,
                'aozora_works_count': author.aozora_works_count,
                'section': author.section,
                'alias_info': author.alias_info,
                'created_at': author.created_at.isoformat() if author.created_at else None,
                'updated_at': author.updated_at.isoformat() if author.updated_at else None
            })
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        export_file = Path("data/full_database_export.json")
        with open(export_file, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'export_date': datetime.now().isoformat(),
                    'total_authors': len(export_data),
                    'total_works': total_works,
                    'copyright_stats': copyright_stats,
                    'section_stats': section_stats
                },
                'authors': export_data
            }, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å®Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ {export_file} ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
        
        # æœ€çµ‚çµæœ
        print(f"\nğŸ‰ å…¨ä½œå®¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print(f"å‡¦ç†æ™‚é–“: {processing_time:.1f}ç§’")
        print(f"å‡¦ç†é€Ÿåº¦: {len(authors)/processing_time:.1f}ä½œå®¶/ç§’")
        
        session.close()
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 