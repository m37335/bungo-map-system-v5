#!/usr/bin/env python3
"""
v5.0ç§»è¡Œãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ–°ãƒ†ãƒ¼ãƒ–ãƒ«ã€ãƒ¢ãƒ‡ãƒ«ã€åŸºæœ¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ

ä½œæˆæ—¥: 2025å¹´6æœˆ25æ—¥
"""

import os
import sys
import tempfile
import sqlite3
import json
from datetime import datetime

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def test_schema_creation():
    """ã‚¹ã‚­ãƒ¼ãƒä½œæˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ã‚¹ã‚­ãƒ¼ãƒä½œæˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_db:
        db_path = tmp_db.name
    
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # schema_v5.sqlã®å†…å®¹ã‚’å®Ÿè¡Œ
            schema_sql = """
            CREATE TABLE sections (
                section_id INTEGER PRIMARY KEY AUTOINCREMENT,
                work_id INTEGER NOT NULL,
                section_type VARCHAR(20) NOT NULL CHECK (section_type IN ('chapter', 'paragraph', 'sentence')),
                parent_section_id INTEGER,
                section_number INTEGER,
                title VARCHAR(200),
                content TEXT,
                character_position INTEGER,
                character_length INTEGER,
                metadata JSON,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );

            CREATE TABLE ai_verifications (
                verification_id INTEGER PRIMARY KEY AUTOINCREMENT,
                place_mention_id INTEGER NOT NULL,
                ai_model VARCHAR(50) NOT NULL,
                verification_type VARCHAR(50) NOT NULL,
                input_context TEXT,
                ai_response JSON,
                confidence_score DECIMAL(3, 2),
                is_valid_place BOOLEAN,
                reasoning TEXT,
                verification_status VARCHAR(20) DEFAULT 'pending',
                processing_time_ms INTEGER,
                api_cost DECIMAL(8, 6),
                verified_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );

            CREATE TABLE statistics_cache (
                cache_id INTEGER PRIMARY KEY AUTOINCREMENT,
                cache_key VARCHAR(200) NOT NULL UNIQUE,
                cache_type VARCHAR(50) NOT NULL,
                entity_id INTEGER,
                data JSON NOT NULL,
                expires_at DATETIME,
                hit_count INTEGER DEFAULT 0,
                last_accessed DATETIME,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );

            CREATE TABLE processing_logs (
                log_id INTEGER PRIMARY KEY AUTOINCREMENT,
                work_id INTEGER,
                process_type VARCHAR(50) NOT NULL,
                status VARCHAR(20) NOT NULL DEFAULT 'started',
                started_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                completed_at DATETIME,
                processing_duration_ms INTEGER,
                error_message TEXT,
                statistics JSON,
                configuration JSON
            );
            """
            
            cursor.executescript(schema_sql)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            expected_tables = ['sections', 'ai_verifications', 'statistics_cache', 'processing_logs']
            for table in expected_tables:
                assert table in tables, f"ãƒ†ãƒ¼ãƒ–ãƒ« {table} ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
                
            print("âœ… ã‚¹ã‚­ãƒ¼ãƒä½œæˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if os.path.exists(db_path):
            os.unlink(db_path)

def test_models_import():
    """ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
        from database.models import Section, AIVerification, StatisticsCache, ProcessingLog
        print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # Pydanticãƒ¢ãƒ‡ãƒ«
        from core.models import (
            SectionBase, SectionCreate, SectionResponse,
            AIVerificationBase, AIVerificationCreate, AIVerificationResponse,
            StatisticsCacheBase, StatisticsCacheCreate, StatisticsCacheResponse,
            ProcessingLogBase, ProcessingLogCreate, ProcessingLogResponse,
            SectionType, VerificationType, VerificationStatus, CacheType, ProcessType, ProcessStatus
        )
        print("âœ… Pydanticãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # Enumãƒ†ã‚¹ãƒˆ
        assert SectionType.CHAPTER == "chapter"
        assert VerificationType.PLACE_VALIDATION == "place_validation"
        assert VerificationStatus.VERIFIED == "verified"
        print("âœ… Enumå€¤ãƒ†ã‚¹ãƒˆæˆåŠŸ")
        
    except ImportError as e:
        print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise

def test_data_operations():
    """ãƒ‡ãƒ¼ã‚¿æ“ä½œãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒ‡ãƒ¼ã‚¿æ“ä½œãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_db:
        db_path = tmp_db.name
    
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute("""
                CREATE TABLE statistics_cache (
                    cache_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    cache_key VARCHAR(200) NOT NULL UNIQUE,
                    cache_type VARCHAR(50) NOT NULL,
                    entity_id INTEGER,
                    data JSON NOT NULL,
                    expires_at DATETIME,
                    hit_count INTEGER DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ãƒ†ã‚¹ãƒˆ
            test_data = {"test": "value", "count": 123}
            cursor.execute("""
                INSERT INTO statistics_cache (cache_key, cache_type, data)
                VALUES (?, ?, ?)
            """, ("test_key", "global_stats", json.dumps(test_data)))
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
            cursor.execute("SELECT cache_key, cache_type, data FROM statistics_cache WHERE cache_key = ?", ("test_key",))
            row = cursor.fetchone()
            
            assert row is not None, "ãƒ‡ãƒ¼ã‚¿ãŒæŒ¿å…¥ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            assert row[0] == "test_key", "cache_keyãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“"
            assert row[1] == "global_stats", "cache_typeãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“"
            
            retrieved_data = json.loads(row[2])
            assert retrieved_data == test_data, "JSONãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãä¿å­˜ãƒ»å–å¾—ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            print("âœ… ãƒ‡ãƒ¼ã‚¿æ“ä½œãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
    finally:
        if os.path.exists(db_path):
            os.unlink(db_path)

def test_migration_script():
    """ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    try:
        from database.migration_v4_to_v5 import DatabaseMigrationV5
        
        # ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_db:
            db_path = tmp_db.name
            
        # åŸºæœ¬ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆï¼ˆç§»è¡Œå…ƒï¼‰
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE authors (
                    author_id INTEGER PRIMARY KEY,
                    author_name VARCHAR(255)
                )
            """)
            cursor.execute("INSERT INTO authors (author_name) VALUES ('ãƒ†ã‚¹ãƒˆä½œè€…')")
        
        # ç§»è¡Œãƒ†ã‚¹ãƒˆ
        migrator = DatabaseMigrationV5(db_path, tempfile.mkdtemp())
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆãƒ†ã‚¹ãƒˆ
        backup_path = migrator.create_backup()
        assert os.path.exists(backup_path), "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
        
        # æ–°ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ
        migrator._create_new_tables()
        
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            assert 'sections' in tables, "sectionsãƒ†ãƒ¼ãƒ–ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
            assert 'ai_verifications' in tables, "ai_verificationsãƒ†ãƒ¼ãƒ–ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
        print("âœ… ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        os.unlink(db_path)
        os.unlink(backup_path)
        
    except Exception as e:
        print(f"âŒ ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ v5.0ç§»è¡Œãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    try:
        test_schema_creation()
        test_models_import()
        test_data_operations()
        test_migration_script()
        
        print("=" * 50)
        print("âœ… å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼v5.0ç§»è¡Œæº–å‚™å®Œäº†")
        return 0
        
    except Exception as e:
        print("=" * 50)
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main()) 