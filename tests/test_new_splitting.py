#!/usr/bin/env python3
"""æ–°ã—ã„ã‚»ãƒ³ãƒ†ãƒ³ã‚¹åˆ†å‰²å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""

import sys
sys.path.append('/app/bungo-map-system-v4')

from extractors.fetch_work_content import WorkContentProcessor

def test_new_splitting():
    # ãƒ†ã‚¹ãƒˆç”¨ã®æ–‡ç« 
    test_text = 'ç§ãŒå…ˆç”Ÿã¨çŸ¥ã‚Šåˆã„ã«ãªã£ãŸã®ã¯éŒå€‰ã§ã‚ã‚‹ã€‚ãã®æ™‚ç§ã¯ã¾ã è‹¥ã€…ã—ã„æ›¸ç”Ÿã§ã‚ã£ãŸã€‚æš‘ä¸­ä¼‘æš‡ã‚’åˆ©ç”¨ã—ã¦æµ·æ°´æµ´ã«è¡Œã£ãŸã€‚ã“ã‚Œã¯æœ¬å½“ã«è‰¯ã„æ€ã„å‡ºã ï¼å›ã¯çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ'

    processor = WorkContentProcessor()
    sentences = processor.split_into_sentences(test_text)

    print('ğŸ§ª æ–°ã—ã„ã‚»ãƒ³ãƒ†ãƒ³ã‚¹åˆ†å‰²ãƒ†ã‚¹ãƒˆ:')
    print(f'å…¥åŠ›æ–‡: {test_text}')
    print()
    print('âœ… åˆ†å‰²çµæœï¼ˆå¥èª­ç‚¹ä¿æŒï¼‰:')
    for i, sentence in enumerate(sentences, 1):
        print(f'  {i}. "{sentence}"')
        
    print(f'\nğŸ“Š çµæœ: {len(sentences)}æ–‡ã«åˆ†å‰²ã€ã™ã¹ã¦å¥èª­ç‚¹ä¿æŒæ¸ˆã¿')
    
    # å¥èª­ç‚¹ãƒã‚§ãƒƒã‚¯
    punctuation_count = sum(1 for s in sentences if s.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ')))
    print(f'âœ… å¥èª­ç‚¹ä¿æŒç‡: {punctuation_count}/{len(sentences)} ({punctuation_count/len(sentences)*100:.1f}%)')

if __name__ == "__main__":
    test_new_splitting() 