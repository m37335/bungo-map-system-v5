#!/usr/bin/env python3
"""
æ¢¶äº•åŸºæ¬¡éƒã®URLç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from extractors.author_list_scraper import AuthorListScraper

def main():
    print("ğŸ” æ¢¶äº•åŸºæ¬¡éƒã®URLç¢ºèª")
    print("=" * 40)
    
    try:
        scraper = AuthorListScraper(rate_limit=0.3)
        print("ğŸ“š ä½œå®¶æƒ…å ±å–å¾—ä¸­...")
        authors = scraper.fetch_all_authors()
        
        # æ¢¶äº•åŸºæ¬¡éƒã‚’æ¤œç´¢
        kajii_authors = [a for a in authors if 'æ¢¶äº•' in a.name and 'åŸºæ¬¡éƒ' in a.name]
        
        if kajii_authors:
            kajii = kajii_authors[0]
            print(f"âœ… æ¢¶äº•åŸºæ¬¡éƒã‚’ç™ºè¦‹")
            print(f"ä½œå®¶å: {kajii.name}")
            print(f"å–å¾—URL: {kajii.author_url}")
            print(f"æœŸå¾…URL: https://www.aozora.gr.jp/index_pages/person74.html")
            
            if kajii.author_url == "https://www.aozora.gr.jp/index_pages/person74.html":
                print("ğŸ‰ URLãŒæ­£ã—ãä¿®æ­£ã•ã‚Œã¦ã„ã¾ã™ï¼")
                print("ä½œå“æ•°:", kajii.works_count)
                print("è‘—ä½œæ¨©:", kajii.copyright_status)
            else:
                print("âŒ URLãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™")
        else:
            print("âŒ æ¢¶äº•åŸºæ¬¡éƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
        # ä»–ã®æ¢¶äº•ã•ã‚“ã‚‚ç¢ºèª
        all_kajii = [a for a in authors if 'æ¢¶äº•' in a.name]
        if len(all_kajii) > 1:
            print(f"\nğŸ“– ãã®ä»–ã®æ¢¶äº•ã•ã‚“ ({len(all_kajii)-1}å):")
            for author in all_kajii:
                if author.name != "æ¢¶äº• åŸºæ¬¡éƒ":
                    print(f"  - {author.name}: {author.author_url}")
                    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 